# Memory — 2026-02-20

Time: 2026-02-20 12:27 PM (America/Los_Angeles)

- GPU & runtime
  - Intel Arc A310 successfully passed through to VM 404 (hostpci0: 07:00.0). IOMMU group 107. x-vga=0 retained.
  - Level Zero runtime installed in VM 404; intel-extension-for-pytorch (IPEX) + matching PyTorch ABI installed.
  - torch.xpu.is_available() → True; device detected: "Intel(R) Arc(TM) A310 LP Graphics (3.76 GB)".
  - Verified compute with matrix multiply and NN forward tests (GPU functional; perf varies vs CPU as expected for Arc A310).

- MarkItDown & document conversion
  - markitdown (Python) installed and validated.
  - Full feature set installed: pdfplumber/pypdf/pypdfium2, python-docx, openpyxl, xlrd, pillow, tesseract OCR present.
  - Whisper (openai-whisper) installed and tested; tiny model downloaded and moved to XPU successfully (Whisper uses xpu device).

- Vector search & RAG
  - Vector-search skill created and tested: skills/vector-search with tools for ChromaDB/Qdrant/Milvus; ChromaDB test succeeded.
  - Plan: index Obsidian vault → Chroma/Qdrant and implement RAG wrapper (search results → LLM).

- Search integration
  - SearXNG confirmed running at http://192.168.1.210:8080.
  - Local searxng skill present at skills/searxng and is the supported replacement for built-in tools.web.search; web_search wrapper and TOOLS.md updated to prefer SearXNG (avoids Brave API costs).

- Models & copilot-proxy
  - copilot-proxy provider available with models including gpt-5-mini.
  - Config updated: primary model switched to copilot-proxy/gpt-5-mini, fallback set to anthropic/claude-sonnet-4-5.
  - Gateway restart requested to apply model change (user requested restart). If not yet restarted, gateway needs restart and new sessions to pick up change.
  - Note: copilot-proxy service required to be running for model use; initial probe returned errors but later probe showed models available.

- Packages & tooling installed
  - Installed: langchain, langchain-community, accelerate, datasets, guidance, sentencepiece, tiktoken, etc.
  - llama-cpp-python not yet installed; requires SYCL build for Intel Arc (CMAKE_ARGS="-DGGML_SYCL=on" pip install llama-cpp-python). Planned but pending.

- Observability & automation
  - Vector-search tools planned to expose Prometheus metrics (vector_search_queries_total, vector_search_latency_seconds) and OpenTelemetry spans for MCP calls.
  - Ansible installer and playbook artifacts created for deploying vector infra.

- Pending / Next actions
  - Restart OpenClaw gateway and confirm copilot-proxy/gpt-5-mini is active for new sessions.
  - Index Obsidian vault into a vector store and implement RAG pipeline.
  - Install/compile llama-cpp-python with SYCL for local quantized LLM inference on Arc A310 (if desired).
  - Run bitsandbytes quantization tests (prefer pvet630 for heavy models; small tests OK on VM 404).


-- end of entry
